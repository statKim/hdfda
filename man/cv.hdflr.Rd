% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/hdflr.R
\name{cv.hdflr}
\alias{cv.hdflr}
\title{K-fold cross-validation for \code{hdflr}}
\usage{
cv.hdflr(
  X,
  y,
  grid = NULL,
  penalty = "gr_scad",
  type = "regress",
  basis = "bspline",
  n_basis_list = NULL,
  lambda_list = NULL,
  measure = "accuracy",
  tol = 1e-07,
  K = 5
)
}
\arguments{
\item{X}{a n-m-p array (p-variate functional data; each functional data consists of n curves observed from m timepoints)}

\item{y}{a integer vector containing class label of X (n x 1 vector)}

\item{grid}{a vector containing m timepoints}

\item{penalty}{the penalty type ("gr_scad" is only supported)}

\item{type}{"regress" for regression and "classif" for LDA direction estimation}

\item{basis}{"bspline" is only supported}

\item{n_basis_list}{a vector containing the candidate of \code{n_basis} (the number of cubic B-spline bases using \code{n_basis}-2 knots)}

\item{lambda_list}{a vector containing the candidate of \code{lambda} (a penalty parameter for L1-regularization)}

\item{measure}{the loss function for the cross-validation. "accuracy" or "cross.entropy" (Default is "accuracy")}

\item{tol}{a tolerance rate to define the sparse discriminant set}

\item{K}{the nuber of folds for K-fold CV}
}
\value{
a \code{hdflr} object
}
\description{
Select the optimal \code{n_basis} and \code{lambda} for \code{hdflr} using K-fold cross-validation
Parallel computing can be used by using the \code{doParallel} package usages.
}
